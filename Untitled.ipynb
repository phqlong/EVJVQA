{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3e6c2e-3205-437e-9862-1999f3a1c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using torch==1.8.1+cu101, but torch>=1.10.0 is required to use ViltModel. Please upgrade torch.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Image, Dataset\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from transformers import ViltProcessor, ViltFeatureExtractor, AutoModel, AutoTokenizer, ViltModel, ViltConfig, AutoConfig, VisionEncoderDecoderConfig, VisionEncoderDecoderModel\n",
    "from transformers import BertConfig, ViTConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "\n",
    "import torch, gc\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import warnings\n",
    "from polyglot.detect import Detector\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf79336-8eb1-4ad2-96c9-563eddf72ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_id = [1493, 2397, 2900, 2913, 2952, 2955, 2956, 2959, 2989, 4094, 10008, \n",
    "  10009,\n",
    "  10012,\n",
    "  10082,\n",
    "  10083,\n",
    "  10013,\n",
    "  10014,\n",
    "  10015,\n",
    "  10088,\n",
    "  10018,\n",
    "  10089,\n",
    "  10091,\n",
    "  10022,\n",
    "  10092,\n",
    "  10093,\n",
    "  10023,\n",
    "  10024,\n",
    "  10097,\n",
    "  10028,\n",
    "  10098,\n",
    "  10099,\n",
    "  10101,\n",
    "  10030,\n",
    "  10031,\n",
    "  10033,\n",
    "  10104,\n",
    "  10034,\n",
    "  10035,\n",
    "  10108,\n",
    "  10109,\n",
    "  10110,\n",
    "  10111,\n",
    "  10112,\n",
    "  10113,\n",
    "  10114,\n",
    "  10115,\n",
    "  10044,\n",
    "  10048,\n",
    "  10117,\n",
    "  10118,\n",
    "  10119,\n",
    "  10050,\n",
    "  10051,\n",
    "  10121,\n",
    "  10052,\n",
    "  10125,\n",
    "  10054,\n",
    "  10056,\n",
    "  10127,\n",
    "  10129,\n",
    "  10130,\n",
    "  10131,\n",
    "  10132,\n",
    "  10133,\n",
    "  10134,\n",
    "  10064,\n",
    "  10065,\n",
    "  10135,\n",
    "  10138,\n",
    "  10068,\n",
    "  10069,\n",
    "  10139,\n",
    "  10071,\n",
    "  10142,\n",
    "  10144,\n",
    "  10145,\n",
    "  10146,\n",
    "  10075,\n",
    "  10148,\n",
    "  10149,\n",
    "  10150,\n",
    "  10151,\n",
    "  18584,\n",
    "  20381,\n",
    "  21394,1119,16850,22091,12154,23370,23516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9673b8f4-c833-43a2-8471-b037f8768749",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-901141e54d95>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-901141e54d95>\"\u001b[0;36m, line \u001b[0;32m80\u001b[0m\n\u001b[0;31m    for fold, ( , val) in enumerate(gkf.split(X=df, groups=df.image_id)):\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def is_japanese_sentence(text: str):\n",
    "    pattern = r\"[\\u3000-\\u303F]|[\\u3040-\\u309F]|[\\u30A0-\\u30FF]|[\\uFF00-\\uFFEF]|[\\u4E00-\\u9FAF]|[\\u2605-\\u2606]|[\\u2190-\\u2195]|\\u203B\"\n",
    "    return re.search(pattern, text) is not None\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def detect_lang(s):\n",
    "  try: \n",
    "    return str(Detector(s).language.code)\n",
    "  except Exception as e:\n",
    "    print(f\"error: {e}\\n{s}\")\n",
    "    return \"unk\"\n",
    "\n",
    "def replace_word(lang,length,text):\n",
    "  if (lang == \"ja\") & (length == 1) :\n",
    "    dicts = {\n",
    "        \"2\": \"二\",\n",
    "        \"6\":\"六\",\n",
    "        \"7\":\"七\"\n",
    "    }\n",
    "    for key,value in dicts.items():\n",
    "        text =text.replace(value,key)\n",
    "    return text\n",
    "    for key,value in dicts.items():\n",
    "        text =text.replace(value,key)\n",
    "    return text\n",
    "  elif (lang == \"vi\") & (length == 1) :\n",
    "    dicts = {\n",
    "        \"hai\": \"2\",\n",
    "        \"ba\":\"3\",\n",
    "    }\n",
    "    for key,value in dicts.items():\n",
    "        text =text.replace(value,key)\n",
    "    return text\n",
    "  else: return text\n",
    "  \n",
    "\n",
    "\n",
    "def read_df(image_folder, data_file,train = False):\n",
    "    \n",
    "    f = open(data_file)\n",
    "    data = json.load(f)\n",
    "    print(\"length data after preprocessing: \",len(data[\"annotations\"]))\n",
    "\n",
    "    img_df = pd.DataFrame.from_records(data['images'])\n",
    "    ann_df = pd.DataFrame.from_records(data['annotations'])\n",
    "    img_df.rename(columns={\"id\": \"image_id\"}, inplace= True)\n",
    "    img_df['image'] = img_df['filename'].apply(\n",
    "        lambda x: f\"{image_folder}/{x}\"\n",
    "    )\n",
    "    df = pd.merge(img_df, ann_df, on=\"image_id\")\n",
    "    df[\"lang_ques\"] = df[\"question\"].apply(lambda x: detect_lang(x))\n",
    "    df[\"length_ans\"] = df[\"answer\"].apply(lambda x: len(list(x)) if is_japanese_sentence(x) else len(x.split()) )\n",
    "    if train:\n",
    "      # q&a not same language\n",
    "      df = df[~df['id'].isin(black_id)]\n",
    "      \n",
    "      df[\"answer\"] = df.apply(lambda x: replace_word(x.lang_ques, x.length_ans, x.answer), axis=1)\n",
    "      print(\"length data before preprocessing: \",len(df))\n",
    "      return df.reset_index()\n",
    "    else: return df.reset_index()\n",
    "\n",
    "def df_to_dataset(df):\n",
    "    dataset = Dataset.from_pandas(df, preserve_index = False).cast_column(\"image\", Image())\n",
    "    dataset = dataset.remove_columns(['filename','length_ans'])\n",
    "    return dataset\n",
    "\n",
    "df = read_df(CFG.IN_DIR/'train-images', CFG.IN_DIR/'evjvqa_train.json',True)\n",
    "\n",
    "gkf = GroupKFold(n_splits=CFG.kfold)\n",
    "for fold, ( , val) in enumerate(gkf.split(X=df, groups=df.image_id)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "\n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "train_df = df[df[\"kfold\"] != CFG.fold]\n",
    "eval_df = df[df[\"kfold\"] == CFG.fold]\n",
    "\n",
    "train_ds = df_to_dataset(train_df).remove_columns(['kfold'])\n",
    "eval_ds = df_to_dataset(eval_df).remove_columns(['kfold'])\n",
    "print('train_ds', len(train_ds))\n",
    "print('eval_ds', len(eval_ds))\n",
    "\n",
    "test_df = read_df(CFG.IN_DIR/'public-test-images',  CFG.IN_DIR/'official_evjvqa_public_test.json')\n",
    "test_ds = df_to_dataset(test_df)\n",
    "print('test_ds', len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe78edb-c657-4e5c-bbac-e73b3ac8b4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
